{"meta":{"title":"Cloni","subtitle":"","description":"","author":"Li Beibu","url":"http://yoursite.com","root":"/"},"pages":[{"title":"about","date":"2021-05-14T13:44:54.000Z","updated":"2021-05-14T13:50:17.884Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"关于我"},{"title":"categories","date":"2021-05-12T14:49:49.000Z","updated":"2021-05-13T16:11:39.848Z","comments":false,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-05-12T14:36:33.000Z","updated":"2021-05-13T16:09:47.773Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"数组中两个数的最大异或值","slug":"数组中两个数的最大异或值","date":"2021-05-27T11:31:45.000Z","updated":"2021-05-27T13:58:16.955Z","comments":true,"path":"2021/05/27/数组中两个数的最大异或值/","link":"","permalink":"http://yoursite.com/2021/05/27/%E6%95%B0%E7%BB%84%E4%B8%AD%E4%B8%A4%E4%B8%AA%E6%95%B0%E7%9A%84%E6%9C%80%E5%A4%A7%E5%BC%82%E6%88%96%E5%80%BC/","excerpt":"原题链接 给你一个整数数组 nums ，返回 nums[i] XOR nums[j] 的最大运算结果，其中 0 ≤ i ≤ j &lt; n 。 进阶：你可以在 O(n) 的时间解决这个问题吗？","text":"原题链接 给你一个整数数组 nums ，返回 nums[i] XOR nums[j] 的最大运算结果，其中 0 ≤ i ≤ j &lt; n 。 进阶：你可以在 O(n) 的时间解决这个问题吗？ 示例 1： 输入：nums = [3,10,5,25,2,8]输出：28解释：最大运算结果是 5 XOR 25 = 28. 示例 2： 输入：nums = [0]输出：0 示例 3： 输入：nums = [2,4]输出：6 示例 4： 输入：nums = [8,10,2]输出：10 示例 5： 输入：nums = [14,70,53,83,49,91,36,80,92,51,66,70]输出：127 提示： 1 &lt;= nums.length &lt;= 2 * 1040 &lt;= nums[i] &lt;= 231 - 1 解题思路乍一看似乎不难，只需创建一个矩阵，遍历每个数，进行异或运算找到最大值即可 但明显两个循环是O（n^2)超时了 首先我们知道: 异或运算：相同得0，不同为1。又因为我们想要寻找最大的运算结果，因此希望结果有尽可能多的1，且分布在高位上。 s = x ^ y =&gt; x = s ^ y 根据1，想到了贪心算法，从高位开始，贪1 代码如下： 1234567891011121314151617181920212223242526272829class Solution: def findMaximumXOR(self, nums: List[int]) -&gt; int: HIGH_BIT = len(format(max(nums), &#x27;b&#x27;)) /*format:格式化，将内容转为二进制*/ ans = 0 for k in range(HIGH_BIT, -1, -1): # 从高位向地位遍历 seen = set(i &gt;&gt; k for i in nums) # 把nums里的数都右移k位 ans = ans * 2 + 1 /* 把ans末尾加一位1 ans表示当前位数所能异或得到的最大值 */ for i in seen: if i ^ ans in seen: # i ^ ans in seen,根据第二条，表示seen里有两个值能异或得到ans break # 说明ans末尾可以取一，进入下一个循环 else: ans -= 1 # 说明没有两个数可以异或得到末尾加一的ans，因此ans末尾变为0 return ans 总结思想有些巧妙，可以反复推敲 思考问题：该算法从高位遍历到低位，对于每一位都去寻找能否有两个数异或得到1，可是最终结果应该是所有的位数都是同样的两个数异或得到？ 因为ans是从0不断乘2，有一个记录的过程，相当于剪枝。对于第x位，ans若取了1，则在后面的循环中，不能异或得到ans[x]==1的数都必然不可能得到 i ^ ans in seen 了。","categories":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"异或","slug":"异或","permalink":"http://yoursite.com/tags/%E5%BC%82%E6%88%96/"},{"name":"贪心","slug":"贪心","permalink":"http://yoursite.com/tags/%E8%B4%AA%E5%BF%83/"}]},{"title":"YEDDA中文版","slug":"YEDDA中文版","date":"2021-05-15T07:48:16.000Z","updated":"2021-05-15T07:53:14.682Z","comments":true,"path":"2021/05/15/YEDDA中文版/","link":"","permalink":"http://yoursite.com/2021/05/15/YEDDA%E4%B8%AD%E6%96%87%E7%89%88/","excerpt":"","text":"安装教程 可以选择原版或者支持python3.x的中文版 BIO转换参考","categories":[{"name":"NLP","slug":"NLP","permalink":"http://yoursite.com/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://yoursite.com/tags/NLP/"},{"name":"YEDDA","slug":"YEDDA","permalink":"http://yoursite.com/tags/YEDDA/"}]},{"title":"NLP_初试模型”","slug":"NLP-初试模型","date":"2021-05-14T14:11:52.000Z","updated":"2021-05-14T15:36:20.993Z","comments":true,"path":"2021/05/14/NLP-初试模型/","link":"","permalink":"http://yoursite.com/2021/05/14/NLP-%E5%88%9D%E8%AF%95%E6%A8%A1%E5%9E%8B/","excerpt":"对数据进行分词，然后构造词向量，使用神经网络、决策树、逻辑回归、朴素贝叶斯、决策树进行模型训练","text":"对数据进行分词，然后构造词向量，使用神经网络、决策树、逻辑回归、朴素贝叶斯、决策树进行模型训练 简单尝试12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import pandas as pddf = pd.read_excel(r&quot;F:\\自然语言项目\\自行车.xlsx&quot;)df.head()import jiebawords= []for i,row in df.iterrows(): word = jieba.cut(row[&#x27;评价&#x27;]) result = &#x27; &#x27;.join(word) words.append(result)from sklearn.feature_extraction.text import CountVectorizervect = CountVectorizer() #将文本转换为数值，构成特征向量X = vect.fit_transform(words)X = X.toarray()words_bag = vect.vocabulary_len(words_bag)pd.DataFrame(X)y = df[&#x27;标签&#x27;]result = []from sklearn.model_selection import train_test_splitX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.1,random_state = 1)# 神经网络from sklearn.neural_network import MLPClassifiermlp = MLPClassifier()mlp.fit(X_train,y_train)mlp_pred = mlp.predict(X_test)mlp_preda = pd.DataFrame() #创建一个空的DataFramea[&#x27;预测值&#x27;] = list(y_test)a[&#x27;实际值&#x27;] = list(mlp_pred)a.head()#查看我们创建的DataFramefrom sklearn.metrics import accuracy_scoremlp_score = accuracy_score(mlp_pred,y_test)result.append([&quot;神经网络&quot;, mlp_score])print(&quot;神经网络准确度：&quot;, mlp_score)# 逻辑回归from sklearn.linear_model import LogisticRegressionlogist = LogisticRegression()logist.fit(X_train, y_train)logist_pred = logist.predict(X_test)logist_score = accuracy_score(logist_pred,y_test)result.append([&quot;逻辑回归&quot;, logist_score])print(&quot;逻辑回归准确度：&quot;, logist_score)# kmeans算法from sklearn.cluster import KMeanskms = KMeans(n_clusters = 2)kms.fit(X)kms_pred = kms.labels_kms_score = accuracy_score(kms_pred, y)result.append([&quot;KMeans&quot;, kms_score])print(&quot;KMeans算法准确度：&quot;, kms_score)# 决策树from sklearn.tree import DecisionTreeClassifiertree = DecisionTreeClassifier(random_state=0)tree.fit(X_train, y_train)tree_pred = tree.predict(X_test)result.append([&quot;决策树&quot;, tree_score])tree_score = accuracy_score(tree_pred, y_test)print(&quot;决策树模型准确度：&quot;, tree_score)# 朴素贝叶斯from sklearn.naive_bayes import GaussianNBnvb = GaussianNB()nvb.fit(X_train, y_train)nvb_pred = nvb.predict(X_test)nvb_score = accuracy_score(nvb_pred, y_test)result.append([&quot;朴素贝叶斯&quot;, nvb_score])print(&quot;朴素贝叶斯模型准确度：&quot;, nvb_score)print(result) 最终结果 12345&gt;[[&#x27;神经网络&#x27;, 0.9666666666666667],[&#x27;逻辑回归&#x27;, 0.9833333333333333],[&#x27;KMeans&#x27;, 0.3983333333333333],[&#x27;决策树&#x27;, 0.8833333333333333],[&#x27;朴素贝叶斯&#x27;, 0.95]] 稍加改进根据分词结果，手动添加了一些常用词，从网上找到一些常用的停用词 在导入数据后，对jieba导入了常用词，然后分词，并去除停用词，然后再进行词向量、模型训练 下面是改进后的分词的代码，后面词向量和模型训练的代码不变 123456789101112131415161718# 导入停用词和常用词stop = open(&#x27;F:\\自然语言项目\\停用词.txt&#x27;, &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;)stopWord = stop.read().split(&quot;\\n&quot;)jieba.load_userdict(&quot;F:\\自然语言项目\\常用词库.txt&quot;)# 分词import jiebawords = []for i,row in df.iterrows(): word = jieba.cut(row[&#x27;评价&#x27;]) s = list(word) r = [] for j in s: if not(j.strip() in stopWord): r.append(j) result = &#x27; &#x27;.join(r) words.append(result) 最终结果 12345&gt;[[&#x27;神经网络&#x27;, 0.9833333333333333],[&#x27;逻辑回归&#x27;, 1.0],[&#x27;KMeans&#x27;, 0.3983333333333333],[&#x27;决策树&#x27;, 0.9333333333333333],[&#x27;朴素贝叶斯&#x27;, 0.9666666666666667]] 可以看到，几个模型的准确度都显著提升 可是逻辑回归准确度1？？？这合理吗？？ 目前代码没有发现问题，后续跟进 总结逻辑回归效果较好 神经网络效果也不错 kmeans效果较差","categories":[{"name":"NLP","slug":"NLP","permalink":"http://yoursite.com/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://yoursite.com/tags/NLP/"},{"name":"jieba","slug":"jieba","permalink":"http://yoursite.com/tags/jieba/"}]},{"title":"停在原地的方案数","slug":"停在原地的方案数","date":"2021-05-13T14:33:09.000Z","updated":"2021-05-27T11:34:28.717Z","comments":true,"path":"2021/05/13/停在原地的方案数/","link":"","permalink":"http://yoursite.com/2021/05/13/%E5%81%9C%E5%9C%A8%E5%8E%9F%E5%9C%B0%E7%9A%84%E6%96%B9%E6%A1%88%E6%95%B0/","excerpt":"原题链接 有一个长度为 arrLen 的数组，开始有一个指针在索引 0 处。 每一步操作中，你可以将指针向左或向右移动 1 步，或者停在原地（指针不能被移动到数组范围外）。 给你两个整数 steps 和 arrLen ，请你计算并返回：在恰好执行 steps 次操作以后，指针仍然指向索引 0 处的方案数。 由于答案可能会很大，请返回方案数 模 10^9 + 7 后的结果。","text":"原题链接 有一个长度为 arrLen 的数组，开始有一个指针在索引 0 处。 每一步操作中，你可以将指针向左或向右移动 1 步，或者停在原地（指针不能被移动到数组范围外）。 给你两个整数 steps 和 arrLen ，请你计算并返回：在恰好执行 steps 次操作以后，指针仍然指向索引 0 处的方案数。 由于答案可能会很大，请返回方案数 模 10^9 + 7 后的结果。 示例 1： 输入：steps = 3, arrLen = 2输出：4解释：3 步后，总共有 4 种不同的方法可以停在索引 0 处。向右，向左，不动不动，向右，向左向右，不动，向左不动，不动，不动 示例 2： 输入：steps = 2, arrLen = 4输出：2解释：2 步后，总共有 2 种不同的方法可以停在索引 0 处。向右，向左不动，不动 下面是一开始我用的递归的方法，也能实现，但超时了 12345678910111213141516171819202122232425262728result = 0class Solution: def numWays(self, steps: int, arrLen: int) -&gt; int: # 写函数，参数有 当前位置，剩下步数 # 每次向前右、向左、不动 三个递归 global result result = 0 def move(index, left_steps): global result f = 1 # 1表示可以继续，0表示不能继续 if left_steps &lt; index: # 剩余步数小于当前位置，表示无法回到原位 f = 0 elif index == 0 and left_steps ==0: # 刚好回到原位 result += 1 f = 0 elif index &lt; 0 or index &gt;=arrLen: f = 0 elif left_steps == index: result +=1 f = 0 if f == 1: move(index + 1, left_steps - 1) move(index - 1, left_steps - 1) move(index, left_steps - 1) move(0, steps) s = 10**9 + 7 return result % s 下面是正确的使用动态规划的方法 1234567891011121314151617181920212223class Solution: def numWays(self, steps: int, arrLen: int) -&gt; int: mod = 10**9 + 7 maxColumn = min(arrLen - 1, steps) # 最大下标 # dp[i][j]表示通过i次走到位置j的方案数 # range函数范围：[0, steps + 1 ) # maxColumn是最大下标，因此开辟的空间数是maxColumn+1 # 经过0次，到达除了0以外的位置的方案数都是0 dp = [[0] * (maxColumn + 1) for _ in range(steps + 1)] dp[0][0] = 1 # 最开始一定在位置0，因此经过0步，到位置0的方案是1 for i in range(1, steps + 1): # range函数前开后闭，因此+1 for j in range(0, maxColumn + 1): dp[i][j] = dp[i - 1][j] # dp[i][j]一定可以由上一步&quot;不动&quot;得到 if j &gt;= 1: # 如果j大于1的话，就一定可以由前面一个位置右移过来（j==0的话在最左边，不可能右移得到） dp[i][j] = (dp[i][j] + dp[i - 1][j - 1]) % mod if j &lt;= maxColumn - 1: # 类似的，j小于maxColumn-1（ dp[i][j] = (dp[i][j] + dp[i - 1][j + 1]) % mod return dp[steps][0] # 返回经过steps此走到位置0的方案数 动态规划基本思想：将问题划分为更小的子问题，由众多子问题得到原问题的解 比前面我自己的方法快就快在，他用数组记录了各个子问题的解（一开始我也想到了用数组记录，但后面方向错了，最后放弃，终究还是对动态规划不够熟悉，白学了白学了…） 关键思想：dp*[i][j]=dp[i−1][j−1]+dp[i−1][j]+dp[i−1][j+1] 即每一个状态都可以由其他状态经过左移或右移或不动得到，因此在不越界的情况下，每一个状态的方案数都可以由前面的三个状态的方案数相加得到， 因此遍历每一次运动（这里要注意，需要记录第0次的方案数，因为第一次，即i==1的时候的数据是由i==0得到的），每一个下标，不断完善二维数组，得到答案。 复杂度分析 时间复杂度：O(steps×min(arrLen,steps)。动态规划需要计算每个状态的值。 空间复杂度：O(min(arrLen,steps)。使用空间优化的做法，可以将空间复杂度降低到 O(min(arrLen,steps) 总结动态规划：将大问题分解成众多简单小问题，由小问题得到大问题 别总想着递归递归了！浪费时间！（不过确实真香）","categories":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"http://yoursite.com/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"}]}],"categories":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"NLP","slug":"NLP","permalink":"http://yoursite.com/categories/NLP/"}],"tags":[{"name":"异或","slug":"异或","permalink":"http://yoursite.com/tags/%E5%BC%82%E6%88%96/"},{"name":"贪心","slug":"贪心","permalink":"http://yoursite.com/tags/%E8%B4%AA%E5%BF%83/"},{"name":"NLP","slug":"NLP","permalink":"http://yoursite.com/tags/NLP/"},{"name":"YEDDA","slug":"YEDDA","permalink":"http://yoursite.com/tags/YEDDA/"},{"name":"jieba","slug":"jieba","permalink":"http://yoursite.com/tags/jieba/"},{"name":"动态规划","slug":"动态规划","permalink":"http://yoursite.com/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"}]}